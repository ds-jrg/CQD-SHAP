{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be748b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.id2node = {}\n",
    "        self.node2id = {}\n",
    "        self.id2rel = {}\n",
    "        self.rel2id = {}\n",
    "        self.node2title = {}\n",
    "        self.title2node = {}\n",
    "\n",
    "    def load_key_value_files(self, filename):\n",
    "        '''\n",
    "        Load key-value pairs from a file\n",
    "        Args:\n",
    "            filename (str): The name of the file to load.\n",
    "            file_format (str): The format of the file ('pkl' or 'txt').\n",
    "        Returns:\n",
    "            tuple: (id2value, value2id) where:\n",
    "                id2value (dict): Dictionary mapping IDs to values.\n",
    "                value2id (dict): Dictionary mapping values to IDs.\n",
    "        '''\n",
    "        id2value = {}\n",
    "        value2id = {}\n",
    "        file_format = filename.split('.')[-1]\n",
    "        if file_format == 'pkl':\n",
    "            with open(filename, 'rb') as f:\n",
    "                id2value = pickle.load(f)\n",
    "        elif file_format == 'txt':\n",
    "            with open(filename, 'r') as f:\n",
    "                id2value = {}\n",
    "                for line in f:\n",
    "                    id, value = line.strip().split('\\t')\n",
    "                    id2value[id] = value\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Use 'pkl' or 'txt'.\")\n",
    "        value2id = {v: k for k, v in id2value.items()}\n",
    "        return id2value, value2id\n",
    "    \n",
    "    def set_id2node(self, filename):\n",
    "        id2node, node2id = self.load_key_value_files(filename)\n",
    "        self.id2node = id2node\n",
    "        self.node2id = node2id\n",
    "        print(f\"Loaded {len(self.id2node)} nodes from {filename}.\")\n",
    "\n",
    "    def get_node_by_id(self, node_id):\n",
    "        return self.id2node.get(node_id, None)\n",
    "    \n",
    "    def get_id_by_node(self, node):\n",
    "        return self.node2id.get(node, None)\n",
    "\n",
    "    def set_id2rel(self, filename):\n",
    "        id2rel, rel2id = self.load_key_value_files(filename)\n",
    "        self.id2rel = id2rel\n",
    "        self.rel2id = rel2id\n",
    "        print(f\"Loaded {len(self.id2rel)} relations from {filename}.\")\n",
    "\n",
    "    def get_relation_by_id(self, rel_id):\n",
    "        return self.id2rel.get(rel_id, None)\n",
    "    \n",
    "    def get_id_by_relation(self, relation):\n",
    "        return self.rel2id.get(relation, None)\n",
    "\n",
    "    def set_node2title(self, filename):\n",
    "        node2title, title2node = self.load_key_value_files(filename)\n",
    "        self.node_to_title = node2title\n",
    "        self.title2node = title2node\n",
    "        print(f\"Loaded {len(self.node_to_title)} node titles from {filename}.\")\n",
    "\n",
    "\n",
    "    def get_title_by_node(self, node):\n",
    "        return self.node_to_title.get(node, None)\n",
    "    \n",
    "    def get_node_by_title(self, title):\n",
    "        return self.title2node.get(title, None)\n",
    "    \n",
    "    def get_num_nodes(self):\n",
    "        return len(self.id2node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d72620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name: str, id: int, title: str):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.title = title\n",
    "\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_title(self):\n",
    "        return self.title\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, name:str, id: int, head: Node, tail: Node):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.head = head\n",
    "        self.tail = tail\n",
    "\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "    def get_head(self):\n",
    "        return self.head\n",
    "\n",
    "    def get_tail(self):\n",
    "        return self.tail\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, dataset: Dataset):\n",
    "        self.dataset = dataset\n",
    "        self.edges = []\n",
    "    \n",
    "    def add_edge(self, head: str, relation: str, tail: str, skip_missing: bool = True, add_reverse: bool = True):\n",
    "        head_id = self.dataset.get_id_by_node(head)\n",
    "        tail_id = self.dataset.get_id_by_node(tail)\n",
    "        relation_id = self.dataset.get_id_by_relation(relation)\n",
    "        if head_id is None and skip_missing:\n",
    "            print(f'Node {head} not found in dataset, skipping edge')\n",
    "        elif tail_id is None and skip_missing:\n",
    "            print(f'Node {tail} not found in dataset, skipping edge')\n",
    "        elif relation_id is None and skip_missing:\n",
    "            print(f'Relation {relation} not found in dataset, skipping edge')\n",
    "        else:\n",
    "            head_node = Node(head, head_id, self.dataset.get_title_by_node(head))\n",
    "            tail_node = Node(tail, tail_id, self.dataset.get_title_by_node(tail))\n",
    "            edge = Edge(relation, relation_id, head_node, tail_node)\n",
    "            self.edges.append(edge)\n",
    "            if add_reverse:\n",
    "                reverse_relation = f'{relation}_reverse'\n",
    "                reverse_relation_id = self.dataset.get_id_by_relation(reverse_relation)\n",
    "                reverse_edge = Edge(reverse_relation, reverse_relation_id, tail_node, head_node)\n",
    "                self.edges.append(reverse_edge)\n",
    "\n",
    "    def load_triples(self, filename: str, skip_missing: bool = True, add_reverse: bool = True):\n",
    "        try:\n",
    "            with open(filename, 'r') as f:\n",
    "                for line in f:\n",
    "                    head, relation, tail = line.strip().split('\\t')\n",
    "                    self.add_edge(head, relation, tail, skip_missing, add_reverse)\n",
    "        except FileNotFoundError:\n",
    "            raise ValueError(f'File {filename} not found')\n",
    "        except Exception as e:\n",
    "            raise ValueError(f'Error loading triples from {filename}: {e}')\n",
    "        \n",
    "    def get_num_edges(self):\n",
    "        return len(self.edges)\n",
    "    \n",
    "    def get_edges(self):\n",
    "        return self.edges\n",
    "\n",
    "    def get_num_nodes(self):\n",
    "        return self.dataset.get_num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411ceabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14505 nodes from data/FB15k-237/ind2ent.pkl.\n",
      "Loaded 474 relations from data/FB15k-237/ind2rel.pkl.\n",
      "Loaded 14951 node titles from data/FB15k-237/extra/entity2text.txt.\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "\n",
    "data_dir = 'data/FB15k-237'\n",
    "dataset.set_id2node(f'{data_dir}/ind2ent.pkl')\n",
    "dataset.set_id2rel(f'{data_dir}/ind2rel.pkl')\n",
    "dataset.set_node2title(f'{data_dir}/extra/entity2text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "112eb647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14505, 544230)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_train = Graph(dataset)\n",
    "graph_train.load_triples(f'{data_dir}/train.txt', skip_missing=False, add_reverse=True)\n",
    "graph_train.get_num_nodes(), graph_train.get_num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc1a98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14505, 579300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_valid = Graph(dataset)\n",
    "# add training edges to validation graph\n",
    "for edge in graph_train.get_edges():\n",
    "    # we set add_reverse=False because it already exists in the training graph\n",
    "    graph_valid.add_edge(edge.get_head().get_name(), edge.get_name(), edge.get_tail().get_name(), skip_missing=False, add_reverse=False)\n",
    "graph_valid.load_triples(f'{data_dir}/valid.txt', skip_missing=False, add_reverse=True)\n",
    "graph_valid.get_num_nodes(), graph_valid.get_num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e84dd55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14505, 620232)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_test = Graph(dataset)\n",
    "# add training and validation edges to test graph (validation graph contains all training edges)\n",
    "for edge in graph_valid.get_edges():\n",
    "    # we set add_reverse=False because it already exists in the validation graph\n",
    "    graph_test.add_edge(edge.get_head().get_name(), edge.get_name(), edge.get_tail().get_name(), skip_missing=False, add_reverse=False)\n",
    "graph_test.load_triples(f'{data_dir}/test.txt', skip_missing=False, add_reverse=True)\n",
    "graph_test.get_num_nodes(), graph_test.get_num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c775c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, query_type: str, query_answer: tuple):\n",
    "        self.query_type = query_type\n",
    "        if len(query_answer) != 2:\n",
    "            raise ValueError(\"Query answer must be a tuple of (query, answer)\")\n",
    "        elif type(query_answer[1]) is not list:\n",
    "            raise ValueError(\"Query answer must be a tuple of (query, answer) where answer is a list\")\n",
    "        self.query = query_answer[0]\n",
    "        self.answer = query_answer[1]\n",
    "\n",
    "    def get_query(self):\n",
    "        return self.query\n",
    "    \n",
    "    def get_answer(self):\n",
    "        return self.answer\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Query(type={self.query_type}, query={self.query}, answer={self.answer})\"\n",
    "    \n",
    "\n",
    "class QueryDataset:\n",
    "    def __init__(self, dataset: Dataset):\n",
    "        self.dataset = dataset\n",
    "        self.queries = {}\n",
    "\n",
    "    def add_query(self, query_type: str, query_answer: tuple):\n",
    "        if query_type not in self.queries:\n",
    "            self.queries[query_type] = []\n",
    "        query = Query(query_type, query_answer)\n",
    "        self.queries[query_type].append(query)\n",
    "\n",
    "    def get_queries(self, query_type: str):\n",
    "        if query_type not in self.queries:\n",
    "            raise ValueError(f\"No queries of type {query_type} found\")\n",
    "        return self.queries[query_type]\n",
    "    \n",
    "    def get_all_queries(self):\n",
    "        all_queries = []\n",
    "        for query_type, queries in self.queries.items():\n",
    "            all_queries.extend(queries)\n",
    "        return all_queries\n",
    "    \n",
    "    def get_num_queries(self):\n",
    "        return sum(len(queries) for queries in self.queries.values())\n",
    "    \n",
    "    def get_num_queries_by_type(self, query_type: str):\n",
    "        if query_type not in self.queries:\n",
    "            return 0\n",
    "        return len(self.queries[query_type])\n",
    "    \n",
    "    def load_queries_from_pkl(self, filename: str, query_type: str = ''):\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                queries = pickle.load(f)\n",
    "                for query, answer in queries.items():\n",
    "                    answer = list(answer)\n",
    "                    self.add_query(query_type, (query, answer))\n",
    "        except FileNotFoundError:\n",
    "            raise ValueError(f'File {filename} not found')\n",
    "        except Exception as e:\n",
    "            raise ValueError(f'Error loading queries from {filename}: {e}')\n",
    "        \n",
    "def human_readable(query: Query, dataset: Dataset):\n",
    "    if query.query_type == '2p':\n",
    "        anchor = query.query[0][0]\n",
    "        relations = query.query[0][1]\n",
    "        rel1 = relations[0]\n",
    "        rel2 = relations[1]\n",
    "        anchor_name = dataset.get_node_by_id(anchor)\n",
    "        rel1_name = dataset.get_relation_by_id(rel1)\n",
    "        rel2_name = dataset.get_relation_by_id(rel2)\n",
    "        anchor_title = dataset.get_title_by_node(anchor_name)\n",
    "        answers_titles = [dataset.get_title_by_node(dataset.get_node_by_id(a)) for a in query.answer]\n",
    "        print(f\"Query:\\n{anchor_title}\\t--{rel1_name}-->\\tV\")\n",
    "        print(f\"V\\t--{rel2_name}-->\\t?\")\n",
    "        print(f\"\\nAnswer Set (?): \\n{answers_titles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11664a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class SymbolicReasoning:\n",
    "    def __init__(self, graph: Graph, logging: bool = True):\n",
    "        self.graph = graph\n",
    "        self.logging = logging\n",
    "\n",
    "    def query_1p(self, head: int, relation: int):\n",
    "        if self.logging:\n",
    "            print(f\"Querying for head: {self.graph.dataset.get_title_by_node(self.graph.dataset.get_node_by_id(head))} ({head} | {self.graph.dataset.get_node_by_id(head)}) and relation: {self.graph.dataset.get_relation_by_id(relation)} ({relation})\")\n",
    "        answers = []\n",
    "        edges = self.graph.get_edges()\n",
    "        for edge in edges:\n",
    "            if edge.get_head().get_id() == head and edge.get_id() == relation:\n",
    "                if self.logging:\n",
    "                    print(f\"Found edge: {edge.get_head().get_title()} --{edge.get_name()}--> {edge.get_tail().get_title()} ({edge.get_tail().get_id()})\")\n",
    "                answers.append(edge.get_tail().get_id())\n",
    "        if self.logging:\n",
    "            print(\"-\" * 50)\n",
    "        return list(set(answers))\n",
    "    \n",
    "    def query_2p(self, head: int, relations: tuple):\n",
    "        first_level_answers = self.query_1p(head, relations[0])\n",
    "        second_level_answers = {}\n",
    "        for answer in first_level_answers:\n",
    "            second_level_answers[answer] = self.query_1p(answer, relations[1])\n",
    "        answers_set = set()\n",
    "        for answer, second_level in second_level_answers.items():\n",
    "            for item in second_level:\n",
    "                answers_set.add(item)\n",
    "        return second_level_answers, list(answers_set)\n",
    "    \n",
    "    def fixed_size_answer(self, answers: list, size: int):\n",
    "        # make a dataframe which the index are answers and there is a column called score which the value is 1 for all answers\n",
    "        array = np.full((len(answers), 1), 1)\n",
    "        answers = np.array(answers)\n",
    "        df = pd.DataFrame(array, index=answers, columns=['score'])\n",
    "        if len(df) < size:\n",
    "            # add random nodes to fill the size\n",
    "            all_nodes = list(self.graph.dataset.id2node.keys())\n",
    "            all_nodes_remaining = [node for node in all_nodes if node not in df.index]\n",
    "            additional_nodes = np.random.choice(all_nodes_remaining, size - len(df), replace=False)\n",
    "            additional_nodes = [int(node) for node in additional_nodes]\n",
    "            # add them with score 0\n",
    "            additional_df = pd.DataFrame(np.zeros((len(additional_nodes), 1)), index=additional_nodes, columns=['score'])\n",
    "            df = pd.concat([df, additional_df])\n",
    "        elif len(df) > size:\n",
    "            # truncate the dataframe to the size\n",
    "            df = df.sample(size, replace=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03614dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_query = 'data/FB15k-237/test_ans_2c_hard.pkl'\n",
    "sample_query_type = '2p'\n",
    "query_dataset = QueryDataset(dataset)\n",
    "query_dataset.load_queries_from_pkl(dir_query, query_type=sample_query_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6530b7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dataset.get_num_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ae472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "Lamar Odom\t--/education/educational_institution/students_graduates./education/education/student_reverse-->\tV\n",
      "V\t--/education/educational_degree/people_with_this_degree./education/education/institution_reverse-->\t?\n",
      "\n",
      "Answer Set (?): \n",
      "['Doctorate']\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 4000\n",
    "query = query_dataset.get_queries(sample_query_type)[sample_idx]\n",
    "human_readable(query, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a287b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(query: Query, answers: list):\n",
    "    correct_answers = set(query.get_answer())\n",
    "    predicted_answers = set(answers)\n",
    "    if len(correct_answers) == 0:\n",
    "        return 0.0\n",
    "    return len(correct_answers.intersection(predicted_answers)) / len(correct_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b92213fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "Lamar Odom\t--/education/educational_institution/students_graduates./education/education/student_reverse-->\tV\n",
      "V\t--/education/educational_degree/people_with_this_degree./education/education/institution_reverse-->\t?\n",
      "\n",
      "Answer Set (?): \n",
      "['Doctorate']\n",
      "Querying for head: Lamar Odom (12324 | /m/02_nkp) and relation: /education/educational_institution/students_graduates./education/education/student_reverse (45)\n",
      "Found edge: Lamar Odom --/education/educational_institution/students_graduates./education/education/student_reverse--> University of Rhode Island (4074)\n",
      "Found edge: Lamar Odom --/education/educational_institution/students_graduates./education/education/student_reverse--> University of Nevada, Las Vegas (9463)\n",
      "--------------------------------------------------\n",
      "Querying for head: University of Rhode Island (4074 | /m/02fjzt) and relation: /education/educational_degree/people_with_this_degree./education/education/institution_reverse (179)\n",
      "Found edge: University of Rhode Island --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> PhD (587)\n",
      "Found edge: University of Rhode Island --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> Bachelor of Science (706)\n",
      "Found edge: University of Rhode Island --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> Bachelor of Arts (1177)\n",
      "--------------------------------------------------\n",
      "Querying for head: University of Nevada, Las Vegas (9463 | /m/01jpqb) and relation: /education/educational_degree/people_with_this_degree./education/education/institution_reverse (179)\n",
      "Found edge: University of Nevada, Las Vegas --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> Bachelor's degree (1566)\n",
      "Found edge: University of Nevada, Las Vegas --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> Bachelor of Arts (1177)\n",
      "--------------------------------------------------\n",
      "Answers from test graph: {4074: [1177, 706, 587], 9463: [1177, 1566]}\n",
      "Final Answers: [1177, 706, 587, 1566]\n",
      "Expected Answers: [3181]\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "reasoner_test = SymbolicReasoning(graph_train)\n",
    "\n",
    "sample_idx = 4000\n",
    "query = query_dataset.get_queries(sample_query_type)[sample_idx]\n",
    "human_readable(query, dataset)\n",
    "\n",
    "middle_steps, answers_test = reasoner_test.query_2p(query.get_query()[0][0], query.get_query()[0][1])\n",
    "print(f\"Answers from test graph: {middle_steps}\")\n",
    "print(f\"Final Answers: {answers_test}\")\n",
    "print(f\"Expected Answers: {query.get_answer()}\")\n",
    "print(f\"Accuracy: {accuracy(query, answers_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf55c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying for head: Lamar Odom (12324 | /m/02_nkp) and relation: /education/educational_institution/students_graduates./education/education/student_reverse (45)\n",
      "Found edge: Lamar Odom --/education/educational_institution/students_graduates./education/education/student_reverse--> University of Rhode Island (4074)\n",
      "Found edge: Lamar Odom --/education/educational_institution/students_graduates./education/education/student_reverse--> University of Nevada, Las Vegas (9463)\n",
      "--------------------------------------------------\n",
      "Querying for head: University of Rhode Island (4074 | /m/02fjzt) and relation: /education/educational_degree/people_with_this_degree./education/education/institution_reverse (179)\n",
      "Found edge: University of Rhode Island --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> PhD (587)\n",
      "Found edge: University of Rhode Island --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> Bachelor of Science (706)\n",
      "Found edge: University of Rhode Island --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> Bachelor of Arts (1177)\n",
      "Found edge: University of Rhode Island --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> Bachelor's degree (1566)\n",
      "Found edge: University of Rhode Island --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> Doctorate (3181)\n",
      "--------------------------------------------------\n",
      "Querying for head: University of Nevada, Las Vegas (9463 | /m/01jpqb) and relation: /education/educational_degree/people_with_this_degree./education/education/institution_reverse (179)\n",
      "Found edge: University of Nevada, Las Vegas --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> Bachelor's degree (1566)\n",
      "Found edge: University of Nevada, Las Vegas --/education/educational_degree/people_with_this_degree./education/education/institution_reverse--> Bachelor of Arts (1177)\n",
      "--------------------------------------------------\n",
      "Answers from test graph: {4074: [706, 587, 3181, 1177, 1566], 9463: [1177, 1566]}\n",
      "Final Answers: [706, 587, 3181, 1177, 1566]\n",
      "Expected Answers: [3181]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "reasoner_test = SymbolicReasoning(graph_test)\n",
    "\n",
    "middle_steps, answers_test = reasoner_test.query_2p(query.get_query()[0][0], query.get_query()[0][1])\n",
    "print(f\"Answers from test graph: {middle_steps}\")\n",
    "print(f\"Final Answers: {answers_test}\")\n",
    "print(f\"Expected Answers: {query.get_answer()}\")\n",
    "print(f\"Accuracy: {accuracy(query, answers_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24ccab3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "511e7fed-d2b4-4ba4-b91b-f324b25e263d",
       "rows": [
        [
         "706",
         "1.0"
        ],
        [
         "587",
         "1.0"
        ],
        [
         "3181",
         "1.0"
        ],
        [
         "1177",
         "1.0"
        ],
        [
         "1566",
         "1.0"
        ],
        [
         "937",
         "0.0"
        ],
        [
         "11469",
         "0.0"
        ],
        [
         "13007",
         "0.0"
        ],
        [
         "9515",
         "0.0"
        ],
        [
         "5785",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11469</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13007</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9515</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5785</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "706      1.0\n",
       "587      1.0\n",
       "3181     1.0\n",
       "1177     1.0\n",
       "1566     1.0\n",
       "937      0.0\n",
       "11469    0.0\n",
       "13007    0.0\n",
       "9515     0.0\n",
       "5785     0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoner_test.fixed_size_answer(answers_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee278ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.0\n",
      "Valid Accuracy: 0.0\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "reasoner_train = SymbolicReasoning(graph_train, logging=False)\n",
    "reasoner_valid = SymbolicReasoning(graph_valid, logging=False)\n",
    "reasoner_test = SymbolicReasoning(graph_test, logging=False)\n",
    "\n",
    "answers_train = reasoner_train.query_2p(query.get_query()[0][0], query.get_query()[0][1])[1]\n",
    "answers_valid = reasoner_valid.query_2p(query.get_query()[0][0], query.get_query()[0][1])[1]\n",
    "answers_test = reasoner_test.query_2p(query.get_query()[0][0], query.get_query()[0][1])[1]\n",
    "\n",
    "print(f\"Train Accuracy: {accuracy(query, answers_train)}\")\n",
    "print(f\"Valid Accuracy: {accuracy(query, answers_valid)}\")\n",
    "print(f\"Test Accuracy: {accuracy(query, answers_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "998da8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def create_cqd_file(query, original_file='data/FB15k-237/FB15k-237_test_hard.pkl', output_file='data/FB15k-237/FB15k-237_test_hard_sample1.pkl'):\n",
    "    with open(original_file, 'rb') as f:\n",
    "        data_hard = pickle.load(f)\n",
    "    \n",
    "    # remove all queries except the first one\n",
    "    data_hard.type1_1chain = [data_hard.type1_1chain[0]]\n",
    "    \n",
    "    # replace the query with the provided one (note that the target is not important here, so we set it to 0)\n",
    "    data_hard.type1_1chain[0].data['raw_chain'] = [query[0][0], query[0][1][0], [0]]\n",
    "    data_hard.type1_1chain[0].data['anchors'] = [query[0][0]]\n",
    "    data_hard.type1_1chain[0].data['optimisable'] = [-1, 0]\n",
    "    data_hard.type1_1chain[0].data['targets'] = [0]\n",
    "    \n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(data_hard, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a08ffaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12324, (45, 179)),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.get_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "412a5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_cqd_file(query.get_query(), output_file='data/FB15k-237/FB15k-237_test_hard_sample.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6deddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from kbc.cqd_co_xcqa import main\n",
    "import pandas as pd\n",
    "\n",
    "def cqd_query(query: Query, sample_path: str, result_path: str, k: int = 10):\n",
    "    \n",
    "    if sample_path is None:\n",
    "        sample_path = 'data/FB15k-237/FB15k-237_test_hard_sample.pkl'\n",
    "    if result_path is None:\n",
    "        result_path = 'scores.pt'\n",
    "\n",
    "    # Create a CQD file with the query\n",
    "    create_cqd_file(query.get_query(), output_file=sample_path)\n",
    "\n",
    "    # Set up the arguments for the CQD model (cqd_co_xcqa)\n",
    "    args = argparse.Namespace(\n",
    "        path = 'FB15k-237',\n",
    "        sample_path = 'data/FB15k-237/FB15k-237_test_hard_sample.pkl',\n",
    "        model_path = 'models/FB15k-237-model-rank-1000-epoch-100-1602508358.pt',\n",
    "        dataset = 'FB15k-237',\n",
    "        mode = 'test',\n",
    "        chain_type = '1_1', # '1_1', '1_2', '2_2', '2_2_disj', '1_3', '2_3', '3_3', '4_3', '4_3_disj', '1_3_joint'\n",
    "        t_norm = 'prod', # 'min', 'prod'\n",
    "        reg = None,\n",
    "        lr = 0.1,\n",
    "        optimizer='adam', # 'adam', 'adagrad', 'sgd'\n",
    "        max_steps = 1000,\n",
    "        sample = True,\n",
    "        result_path = result_path\n",
    "    )\n",
    "\n",
    "    # Run the CQD model\n",
    "    main(args)\n",
    "\n",
    "    # Load the scores\n",
    "    scores = torch.load(result_path)\n",
    "    scores_np = scores.cpu().numpy()\n",
    "\n",
    "    # Create a DataFrame with the scores\n",
    "    df = pd.DataFrame({'score': scores_np[0]})\n",
    "    df = df.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    # Get the top k answers\n",
    "    top_k_answers = df.head(k)\n",
    "    \n",
    "    return top_k_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bce1dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplEx(\n",
      "  (embeddings): ModuleList(\n",
      "    (0): Embedding(14505, 2000, sparse=True)\n",
      "    (1): Embedding(474, 2000, sparse=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "score",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "21ef4301-9221-483e-8f04-b56cf9fd8e54",
       "rows": [
        [
         "9463",
         "10.657951"
        ],
        [
         "4074",
         "10.4556875"
        ],
        [
         "7265",
         "6.0880313"
        ],
        [
         "4683",
         "5.7487836"
        ],
        [
         "1236",
         "5.6706896"
        ],
        [
         "3169",
         "5.650109"
        ],
        [
         "2173",
         "5.561179"
        ],
        [
         "6483",
         "5.5367694"
        ],
        [
         "5153",
         "5.439585"
        ],
        [
         "3895",
         "5.423999"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9463</th>\n",
       "      <td>10.657951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>10.455688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>6.088031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>5.748784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>5.670690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>5.650109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>5.561179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "      <td>5.536769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>5.439585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>5.423999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          score\n",
       "9463  10.657951\n",
       "4074  10.455688\n",
       "7265   6.088031\n",
       "4683   5.748784\n",
       "1236   5.670690\n",
       "3169   5.650109\n",
       "2173   5.561179\n",
       "6483   5.536769\n",
       "5153   5.439585\n",
       "3895   5.423999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cqd_query(query, sample_path='data/FB15k-237/FB15k-237_test_hard_sample.pkl', result_path='scores.pt', k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bca5e1",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20178c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14505 nodes from data/FB15k-237/ind2ent.pkl.\n",
      "Loaded 474 relations from data/FB15k-237/ind2rel.pkl.\n",
      "Loaded 14951 node titles from data/FB15k-237/extra/entity2text.txt.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14505, 544230)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "\n",
    "data_dir = 'data/FB15k-237'\n",
    "dataset.set_id2node(f'{data_dir}/ind2ent.pkl')\n",
    "dataset.set_id2rel(f'{data_dir}/ind2rel.pkl')\n",
    "dataset.set_node2title(f'{data_dir}/extra/entity2text.txt')\n",
    "\n",
    "graph_train = Graph(dataset)\n",
    "graph_train.load_triples(f'{data_dir}/train.txt', skip_missing=False, add_reverse=True)\n",
    "graph_train.get_num_nodes(), graph_train.get_num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "613b9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_query = 'data/FB15k-237/test_ans_2c_hard.pkl'\n",
    "sample_query_type = '2p'\n",
    "query_dataset = QueryDataset(dataset)\n",
    "query_dataset.load_queries_from_pkl(dir_query, query_type=sample_query_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c90a27c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "Lamar Odom\t--/education/educational_institution/students_graduates./education/education/student_reverse-->\tV\n",
      "V\t--/education/educational_degree/people_with_this_degree./education/education/institution_reverse-->\t?\n",
      "\n",
      "Answer Set (?): \n",
      "['Doctorate']\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 4000\n",
    "query = query_dataset.get_queries(sample_query_type)[sample_idx]\n",
    "human_readable(query, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d9166ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query(type=2p, query=((12324, (45, 179)),), answer=[3181])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c05daecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/m/02_nkp'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_node_by_id(12324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "215b18fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'University of Rhode Island'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_title_by_node(\"/m/02fjzt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59535b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'University of Nevada, Las Vegas'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_title_by_node(\"/m/01jpqb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "340ae81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PhD'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_title_by_node(\"/m/04zx3q1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c37891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bachelor of Science'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_title_by_node(\"/m/02h4rq6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02f4447a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doctorate'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_title_by_node(\"/m/02_xgp2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d37c530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query(type=2p, query=((12324, (45, 179)),), answer=[3181])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44025ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "symolic = SymbolicReasoning(graph_train, logging=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "192c4d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c1deccd8-9922-40ad-9f1a-c3498702d69b",
       "rows": [
        [
         "4074",
         "1.0"
        ],
        [
         "9463",
         "1.0"
        ],
        [
         "12364",
         "0.0"
        ],
        [
         "7627",
         "0.0"
        ],
        [
         "11967",
         "0.0"
        ],
        [
         "7422",
         "0.0"
        ],
        [
         "4297",
         "0.0"
        ],
        [
         "12665",
         "0.0"
        ],
        [
         "2372",
         "0.0"
        ],
        [
         "5024",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9463</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12364</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7627</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7422</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12665</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5024</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "4074     1.0\n",
       "9463     1.0\n",
       "12364    0.0\n",
       "7627     0.0\n",
       "11967    0.0\n",
       "7422     0.0\n",
       "4297     0.0\n",
       "12665    0.0\n",
       "2372     0.0\n",
       "5024     0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1 = symolic.query_1p(query.get_query()[0][0], query.get_query()[0][1][0])\n",
    "query1 = symolic.fixed_size_answer(query1, 10)\n",
    "query1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ee7ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: /m/02fjzt | Title: University of Rhode Island\n",
      "Node: /m/01jpqb | Title: University of Nevada, Las Vegas\n",
      "Node: /m/0g0vx | Title: Farmer-GB\n",
      "Node: /m/01vs73g | Title: Rodney Jerkins\n",
      "Node: /m/0r0ss | Title: Pomona\n",
      "Node: /m/06fpsx | Title: The 40-Year-Old Virgin\n",
      "Node: /m/0pmw9 | Title: Paul Shaffer\n",
      "Node: /m/02gnj2 | Title: Len Wein\n",
      "Node: /m/01xdn1 | Title: Goldman Sachs-US\n",
      "Node: /m/01v0fn1 | Title: Keith Forsey\n"
     ]
    }
   ],
   "source": [
    "v_list = query1.index.tolist()\n",
    "for v in v_list:\n",
    "    print(f\"Node: {dataset.get_node_by_id(v)} | Title: {dataset.get_title_by_node(dataset.get_node_by_id(v))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab78f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128388/106647032.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_answers = pd.concat([final_answers, neuro_answers])\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "score",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "path",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "99845c49-8b7e-4d35-8fd4-de5caa662f9f",
       "rows": [
        [
         "1177",
         "8.299611",
         "[(4074, 1.0)]"
        ],
        [
         "706",
         "8.166074",
         "[(4074, 1.0)]"
        ],
        [
         "1566",
         "7.9793415",
         "[(9463, 1.0)]"
        ],
        [
         "1177",
         "7.85583",
         "[(9463, 1.0)]"
        ],
        [
         "1566",
         "7.546796",
         "[(4074, 1.0)]"
        ],
        [
         "706",
         "7.405836",
         "[(9463, 1.0)]"
        ],
        [
         "587",
         "7.1244035",
         "[(4074, 1.0)]"
        ],
        [
         "1019",
         "6.903434",
         "[(4074, 1.0)]"
        ],
        [
         "1330",
         "6.7661304",
         "[(4074, 1.0)]"
        ],
        [
         "1019",
         "6.6210904",
         "[(9463, 1.0)]"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>8.299611</td>\n",
       "      <td>[(4074, 1.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>8.166074</td>\n",
       "      <td>[(4074, 1.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>7.979342</td>\n",
       "      <td>[(9463, 1.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>7.855830</td>\n",
       "      <td>[(9463, 1.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>7.546796</td>\n",
       "      <td>[(4074, 1.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>7.405836</td>\n",
       "      <td>[(9463, 1.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>7.124403</td>\n",
       "      <td>[(4074, 1.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>6.903434</td>\n",
       "      <td>[(4074, 1.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>6.766130</td>\n",
       "      <td>[(4074, 1.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>6.621090</td>\n",
       "      <td>[(9463, 1.0)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score           path\n",
       "1177  8.299611  [(4074, 1.0)]\n",
       "706   8.166074  [(4074, 1.0)]\n",
       "1566  7.979342  [(9463, 1.0)]\n",
       "1177  7.855830  [(9463, 1.0)]\n",
       "1566  7.546796  [(4074, 1.0)]\n",
       "706   7.405836  [(9463, 1.0)]\n",
       "587   7.124403  [(4074, 1.0)]\n",
       "1019  6.903434  [(4074, 1.0)]\n",
       "1330  6.766130  [(4074, 1.0)]\n",
       "1019  6.621090  [(9463, 1.0)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_rel = query.get_query()[0][1][1]\n",
    "final_answers = pd.DataFrame(columns=['score', 'path'])\n",
    "for idx, row in query1.iterrows():\n",
    "    current_query = Query('1p', (((idx, (second_rel,)),), []))\n",
    "    create_cqd_file(current_query.get_query(), output_file='data/FB15k-237/FB15k-237_test_hard_sample.pkl')\n",
    "    neuro_answers = cqd_query(current_query, sample_path='data/FB15k-237/FB15k-237_test_hard_sample.pkl', result_path='scores.pt', k=10)\n",
    "    neuro_answers['score'] = neuro_answers['score'] * row['score']\n",
    "    neuro_answers['path'] = str([(idx, float(row['score']))])\n",
    "    final_answers = pd.concat([final_answers, neuro_answers])\n",
    "\n",
    "final_answers = final_answers.sort_values(by='score', ascending=False)\n",
    "final_answers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce937c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1177, 706, 1566, 1177, 1566, 706, 587, 1019, 1330, 1019]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = final_answers.index.tolist()[:10]\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e08cacea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "Lamar Odom\t--/education/educational_institution/students_graduates./education/education/student_reverse-->\tV\n",
      "V\t--/education/educational_degree/people_with_this_degree./education/education/institution_reverse-->\t?\n",
      "\n",
      "Answer Set (?): \n",
      "['Doctorate']\n"
     ]
    }
   ],
   "source": [
    "human_readable(query, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a51c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 1177, Title: Bachelor of Arts\n",
      "Node ID: 706, Title: Bachelor of Science\n",
      "Node ID: 1566, Title: Bachelor's degree\n",
      "Node ID: 1177, Title: Bachelor of Arts\n",
      "Node ID: 1566, Title: Bachelor's degree\n",
      "Node ID: 706, Title: Bachelor of Science\n",
      "Node ID: 587, Title: PhD\n",
      "Node ID: 1019, Title: Master's Degree\n",
      "Node ID: 1330, Title: Master of Arts\n",
      "Node ID: 1019, Title: Master's Degree\n"
     ]
    }
   ],
   "source": [
    "for answer in answers:\n",
    "    print(f\"Node ID: {answer}, Title: {dataset.get_title_by_node(dataset.get_node_by_id(answer))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_execution(query: Query, k: int = 10, coalition: list = None):\n",
    "    for c in coalition:\n",
    "        if c == 1:\n",
    "            # run the CQD model\n",
    "            pass\n",
    "        elif c == 0:\n",
    "            # run the symbolic reasoning\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown coalition type: {c}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xcqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
